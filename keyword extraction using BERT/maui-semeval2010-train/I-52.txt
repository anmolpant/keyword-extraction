A Unified and General Framework for
Argumentation-based Negotiation
Leila Amgoud
IRIT - CNRS
118, route de Narbonne
31062, Toulouse, France
amgoud@irit.fr
Yannis Dimopoulos
University of Cyprus
75 Kallipoleos Str.
PO Box 20537, Cyprus
yannis@cs.ucy.ac.cy
Pavlos Moraitis
Paris-Descartes University
45 rue des Saints-Pères
75270 Paris Cedex 06, France

pavlos@math-info.univparis5.fr
ABSTRACT
This paper proposes a unified and general framework for
argumentation-based negotiation, in which the role of 
argumentation is formally analyzed. The framework makes it
possible to study the outcomes of an argumentation-based
negotiation. It shows what an agreement is, how it is related
to the theories of the agents, when it is possible, and how
this can be attained by the negotiating agents in this case.
It defines also the notion of concession, and shows in which
situation an agent will make one, as well as how it influences
the evolution of the dialogue.
Categories and Subject Descriptors
I.2.3 [Deduction and Theorem Proving]: 
Nonmonotonic reasoning and belief revision
; I.2.11 [Distributed Artificial Intelligence]: Intelligent
agents
General Terms
Human Factors, Theory
1. INTRODUCTION
Roughly speaking, negotiation is a process aiming at 
finding some compromise or consensus between two or several
agents about some matters of collective agreement, such
as pricing products, allocating resources, or choosing 
candidates. Negotiation models have been proposed for the
design of systems able to bargain in an optimal way with
other agents for example, buying or selling products in 
ecommerce.
Different approaches to automated negotiation have been
investigated, including game-theoretic approaches (which 
usually assume complete information and unlimited 
computation capabilities) [11], heuristic-based approaches which try
to cope with these limitations [6], and argumentation-based
approaches [2, 3, 7, 8, 9, 12, 13] which emphasize the 
importance of exchanging information and explanations between
negotiating agents in order to mutually influence their 
behaviors (e.g. an agent may concede a goal having a small
priority), and consequently the outcome of the dialogue. 
Indeed, the two first types of settings do not allow for the 
addition of information or for exchanging opinions about offers.
Integrating argumentation theory in negotiation provides a
good means for supplying additional information and also
helps agents to convince each other by adequate arguments
during a negotiation dialogue. Indeed, an offer supported
by a good argument has a better chance to be accepted by
an agent, and can also make him reveal his goals or give
up some of them. The basic idea behind an 
argumentationbased approach is that by exchanging arguments, the 
theories of the agents (i.e. their mental states) may evolve, and
consequently, the status of offers may change. For instance,
an agent may reject an offer because it is not acceptable for
it. However, the agent may change its mind if it receives a
strong argument in favor of this offer.
Several proposals have been made in the literature for
modeling such an approach. However, the work is still 
preliminary. Some researchers have mainly focused on relating
argumentation with protocols. They have shown how and
when arguments in favor of offers can be computed and 
exchanged. Others have emphasized on the decision making
problem. In [3, 7], the authors argued that selecting an offer
to propose at a given step of the dialogue is a decision 
making problem. They have thus proposed an 
argumentationbased decision model, and have shown how such a model
can be related to the dialogue protocol.
In most existing works, there is no deep formal analysis
of the role of argumentation in negotiation dialogues. It is
not clear how argumentation can influence the outcome of
the dialogue. Moreover, basic concepts in negotiation such
as agreement (i.e. optimal solutions, or compromise) and
concession are neither defined nor studied.
This paper aims to propose a unified and general framework
for argumentation-based negotiation, in which the role of
argumentation is formally analyzed, and where the existing
systems can be restated. In this framework, a negotiation
dialogue takes place between two agents on a set O of offers,
whose structure is not known. The goal of a negotiation is to
find among elements of O, an offer that satisfies more or less
967
978-81-904262-7-5 (RPS) c 2007 IFAAMAS
the preferences of both agents. Each agent is supposed to
have a theory represented in an abstract way. A theory 
consists of a set A of arguments whose structure and origin are
not known, a function specifying for each possible offer in O,
the arguments of A that support it, a non specified conflict
relation among the arguments, and finally a preference 
relation between the arguments. The status of each argument is
defined using Dung"s acceptability semantics. Consequently,
the set of offers is partitioned into four subsets: acceptable,
rejected, negotiable and non-supported offers. We show how
an agent"s theory may evolve during a negotiation dialogue.
We define formally the notions of concession, compromise,
and optimal solution. Then, we propose a protocol that 
allows agents i) to exchange offers and arguments, and ii) to
make concessions when necessary. We show that dialogues
generated under such a protocol terminate, and even reach
optimal solutions when they exist.
This paper is organized as follows: Section 2 introduces the
logical language that is used in the rest of the paper. 
Section 3 defines the agents as well as their theories. In section
4, we study the properties of these agents" theories. 
Section 5 defines formally an argumentation-based negotiation,
shows how the theories of agents may evolve during a 
dialogue, and how this evolution may influence the outcome of
the dialogue. Two kinds of outcomes: optimal solution and
compromise are defined, and we show when such outcomes
are reached. Section 6 illustrates our general framework
through some examples. Section 7 compares our formalism
with existing ones. Section 8 concludes and presents some
perspectives. Due to lack of space, the proofs are not 
included. These last are in a technical report that we will
make available online at some later time.
2. THE LOGICAL LANGUAGE
In what follows, L will denote a logical language, and ≡
is an equivalence relation associated with it.
From L, a set O = {o1, . . . , on} of n offers is identified, such
that oi, oj ∈ O such that oi ≡ oj. This means that the
offers are different. Offers correspond to the different 
alternatives that can be exchanged during a negotiation dialogue.
For instance, if the agents try to decide the place of their
next meeting, then the set O will contain different towns.
Different arguments can be built from L. The set Args(L)
will contain all those arguments. By argument, we mean a
reason in believing or of doing something. In [3], it has been
argued that the selection of the best offer to propose at a
given step of the dialogue is a decision problem. In [4], it has
been shown that in an argumentation-based approach for
decision making, two kinds of arguments are distinguished:
arguments supporting choices (or decisions), and arguments
supporting beliefs. Moreover, it has been acknowledged that
the two categories of arguments are formally defined in 
different ways, and they play different roles. Indeed, an 
argument in favor of a decision, built both on an agent"s 
beliefs and goals, tries to justify the choice; whereas an 
argument in favor of a belief, built only from beliefs, tries
to destroy the decision arguments, in particular the beliefs
part of those decision arguments. Consequently, in a 
negotiation dialogue, those two kinds of arguments are generally
exchanged between agents. In what follows, the set Args(L)
is then divided into two subsets: a subset Argso(L) of 
arguments supporting offers, and a subset Argsb(L) of arguments
supporting beliefs. Thus, Args(L) = Argso(L) ∪ Argsb(L).
As in [5], in what follows, we consider that the structure of
the arguments is not known.
Since the knowledge bases from which arguments are built
may be inconsistent, the arguments may be conflicting too.
In what follows, those conflicts will be captured by the 
relation RL, thus RL ⊆ Args(L) × Args(L). Three assumptions
are made on this relation: First the arguments supporting
different offers are conflicting. The idea behind this 
assumption is that since offers are exclusive, an agent has to choose
only one at a given step of the dialogue. Note that, the
relation RL is not necessarily symmetric between the 
arguments of Argsb(L). The second hypothesis says that 
arguments supporting the same offer are also conflicting. The
idea here is to return the strongest argument among these
arguments. The third condition does not allow an argument
in favor of an offer to attack an argument supporting a 
belief. This avoids wishful thinking. Formally:
Definition 1. RL ⊆ Args(L) × Args(L) is a conflict
relation among arguments such that:
• ∀a, a ∈ Argso(L), s.t. a = a , a RL a
• a ∈ Argso(L) and a ∈ Argsb(L) such that a RL a
Note that the relation RL is not symmetric. This is due
to the fact that arguments of Argsb(L) may be conflicting
but not necessarily in a symmetric way. In what follows, we
assume that the set Args(L) of arguments is finite, and each
argument is attacked by a finite number of arguments.
3. NEGOTIATING AGENTS THEORIES AND
REASONING MODELS
In this section we define formally the negotiating agents,
i.e. their theories, as well as the reasoning model used by
those agents in a negotiation dialogue.
3.1 Negotiating agents theories
Agents involved in a negotiation dialogue, called 
negotiating agents, are supposed to have theories. In this paper, the
theory of an agent will not refer, as usual, to its mental states
(i.e. its beliefs, desires and intentions). However, it will be
encoded in a more abstract way in terms of the arguments
owned by the agent, a conflict relation among those 
arguments, a preference relation between the arguments, and a
function that specifies which arguments support offers of the
set O. We assume that an agent is aware of all the 
arguments of the set Args(L). The agent is even able to express
a preference between any pair of arguments. This does not
mean that the agent will use all the arguments of Args(L),
but it encodes the fact that when an agent receives an 
argument from another agent, it can interpret it correctly, and it
can also compare it with its own arguments. Similarly, each
agent is supposed to be aware of the conflicts between 
arguments. This also allows us to encode the fact that an agent
can recognize whether the received argument is in conflict
or not with its arguments. However, in its theory, only the
conflicts between its own arguments are considered.
Definition 2 (Negotiating agent theory). Let O
be a set of n offers. A negotiating agent theory is a tuple
A, F, , R, Def such that:
• A ⊆ Args(L).
968 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
• F: O → 2A
s.t ∀i, j with i = j, F(oi) ∩ F(oj) = ∅.
Let AO = ∪F(oi) with i = 1, . . . , n.
• ⊆ Args(L) × Args(L) is a partial preorder denoting
a preference relation between arguments.
• R ⊆ RL such that R ⊆ A × A
• Def ⊆ A × A such that ∀ a, b ∈ A, a defeats b, denoted
a Def b iff:
- a R b, and
- not (b a)
The function F returns the arguments supporting offers in
O. In [4], it has been argued that any decision may have
arguments supporting it, called arguments PRO, and 
arguments against it, called arguments CONS. Moreover, these
two types of arguments are not necessarily conflicting. For
simplicity reasons, in this paper we consider only arguments
PRO. Moreover, we assume that an argument cannot 
support two distinct offers. However, it may be the case that an
offer is not supported at all by arguments, thus F(oi) may
be empty.
Example 1. Let O = {o1, o2, o3} be a set of offers. The
following theory is the theory of agent i:
• A = {a1, a2, a3, a4}
• F(o1) = {a1}, F(o2) = {a2}, F(o3) = ∅. Thus, Ao =
{a1, a2}
• = {(a1, a2), (a2, a1), (a3, a2), (a4, a3)}
• R = {a1, a2), (a2, a1), (a3, a2), (a4, a3)}
• Def = {(a4, a3), (a3, a2)}
From the above definition of agent theory, the following hold:
Property 1.
• Def ⊆ R
• ∀a, a ∈ F(oi), a R a
3.2 The reasoning model
From the theory of an agent, one can define the 
argumentation system used by that agent for reasoning about the
offers and the arguments, i.e. for computing the status of
the different offers and arguments.
Definition 3 (Argumentation system). Let A, F,
, R, Def be the theory of an agent. The argumentation
system of that agent is the pair A, Def .
In [5], different acceptability semantics have been introduced
for computing the status of arguments. These are based
on two basic concepts, defence and conflict-free, defined as
follows:
Definition 4 (Defence/conflict-free). Let S ⊆ A.
• S defends an argument a iff each argument that defeats
a is defeated by some argument in S.
• S is conflict-free iff there exist no a, a in S such that
a Def a .
Definition 5 (Acceptability semantics). Let S be
a conflict-free set of arguments, and let T : 2A
→ 2A
be a
function such that T (S) = {a | a is defended by S}.
• S is a complete extension iff S = T (S).
• S is a preferred extension iff S is a maximal (w.r.t set
⊆) complete extension.
• S is a grounded extension iff it is the smallest (w.r.t
set ⊆) complete extension.
Let E1, . . . , Ex denote the different extensions under a given
semantics.
Note that there is only one grounded extension. It 
contains all the arguments that are not defeated, and those
arguments that are defended directly or indirectly by 
nondefeated arguments.
Theorem 1. Let A, Def the argumentation system 
defined as shown above.
1. It may have x ≥ 1 preferred extensions.
2. The grounded extensions is S = i≥1
T (∅).
Note that when the grounded extension (or the preferred
extension) is empty, this means that there is no acceptable
offer for the negotiating agent.
Example 2. In example 1, there is one preferred 
extension, E = {a1, a2, a4}.
Now that the acceptability semantics is defined, we are ready
to define the status of any argument.
Definition 6 (Argument status). Let A, Def be an
argumentation system, and E1, . . . , Ex its extensions under a
given semantics. Let a ∈ A.
1. a is accepted iff a ∈ Ei, ∀Ei with i = 1, . . . , x.
2. a is rejected iff Ei such that a ∈ Ei.
3. a is undecided iff a is neither accepted nor rejected.
This means that a is in some extensions and not in
others.
Note that A = {a|a is accepted} ∪ {a|a is rejected} ∪ {a|a
is undecided}.
Example 3. In example 1, the arguments a1, a2 and a4
are accepted, whereas the argument a3 is rejected.
As said before, agents use argumentation systems for 
reasoning about offers. In a negotiation dialogue, agents propose
and accept offers that are acceptable for them, and reject
bad ones. In what follows, we will define the status of an
offer. According to the status of arguments, one can define
four statuses of the offers as follows:
Definition 7 (Offers status). Let o ∈ O.
• The offer o is acceptable for the negotiating agent iff
∃ a ∈ F(o) such that a is accepted. Oa = {oi ∈ O,
such that oi is acceptable}.
• The offer o is rejected for the negotiating agent iff ∀
a ∈ F(o), a is rejected. Or = {oi ∈ O, such that oi is
rejected}.
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 969
• The offer o is negotiable iff ∀ a ∈ F(o), a is undecided.
On = {oi ∈ O, such that oi is negotiable}.
• The offer o is non-supported iff it is neither 
acceptable, nor rejected or negotiable. Ons = {oi ∈ O, such
that oi is non-supported offers}.
Example 4. In example 1, the two offers o1 and o2 are
acceptable since they are supported by accepted arguments,
whereas the offer o3 is non-supported since it has no 
argument in its favor.
From the above definitions, the following results hold:
Property 2. Let o ∈ O.
• O = Oa ∪ Or ∪ On ∪ Ons.
• The set Oa may contain more than one offer.
From the above partition of the set O of offers, a preference
relation between offers is defined. Let Ox and Oy be two
subsets of O. Ox Oy means that any offer in Ox is 
preferred to any offer in the set Oy. We can write also for two
offers oi, oj, oi oj iff oi ∈ Ox, oj ∈ Oy and Ox Oy.
Definition 8 (Preference between offers). Let O
be a set of offers, and Oa, Or, On, Ons its partition. Oa
On Ons Or.
Example 5. In example 1, we have o1 o3, and o2 o3.
However, o1 and o2 are indifferent.
4. THE STRUCTURE OF NEGOTIATION 
THEORIES
In this section, we study the properties of the system 
developed above. We first show that in the particular case
where A = AO (ie. all of the agent"s arguments refer to
offers), the corresponding argumentation system will return
at least one non-empty preferred extension.
Theorem 2. Let A, Def an argumentation system such
that A = AO. Then the system returns at least one 
extension E, such that |E| ≥ 1.
We now present some results that demonstrate the 
importance of indifference in negotiating agents, and more 
specifically its relation to acceptable outcomes. We first show that
the set Oa may contain several offers when their 
corresponding accepted arguments are indifferent w.r.t the preference
relation .
Theorem 3. Let o1, o2 ∈ O. o1, o2 ∈ Oa iff ∃ a1 ∈
F(o1), ∃ a2 ∈ F(o2), such that a1 and a2 are accepted and
are indifferent w.r.t (i.e. a b and b a).
We now study acyclic preference relations that are defined
formally as follows.
Definition 9 (Acyclic relation). A relation R on
a set A is acyclic if there is no sequence a1, a2, . . . , an ∈ A,
with n > 1, such that (ai, ai+1) ∈ R and (an, a1) ∈ R, with
1 ≤ i < n.
Note that acyclicity prohibits pairs of arguments a, b such
that a b and b a, ie., an acyclic preference relation
disallows indifference.
Theorem 4. Let A be a set of arguments, R the 
attacking relation of A defined as R ⊆ A × A, and an acyclic
relation on A. Then for any pair of arguments a, b ∈ A,
such that (a, b) ∈ R, either (a, b) ∈ Def or (b, a) ∈ Def (or
both).
The previous result is used in the proof of the following
theorem that states that acyclic preference relations 
sanction extensions that support exactly one offer.
Theorem 5. Let A be a set of arguments, and an
acyclic relation on A. If E is an extension of <A, Def>,
then |E ∩ AO| = 1.
An immediate consequence of the above is the following.
Property 3. Let A be a set of arguments such that A =
AO. If the relation on A is acyclic, then each extension
Ei of <A, Def>, |Ei| = 1.
Another direct consequence of the above theorem is that
in acyclic preference relations, arguments that support offers
can participate in only one preferred extension.
Theorem 6. Let A be a set of arguments, and an
acyclic relation on A. Then the preferred extensions of
A, Def are pairwise disjoint w.r.t arguments of AO.
Using the above results we can prove the main theorem of
this section that states that negotiating agents with acyclic
preference relations do not have acceptable offers.
Theorem 7. Let A, F, R, , Def be a negotiating
agent such that A = AO and is an acyclic relation. Then
the set of accepted arguments w.r.t A, Def is emtpy. 
Consequently, the set of acceptable offers, Oa is empty as well.
5. ARGUMENTATION-BASED NEGOTIATION
In this section, we define formally a protocol that 
generates argumentation-based negotiation dialogues between
two negotiating agents P and C. The two agents 
negotiate about an object whose possible values belong to a set
O. This set O is supposed to be known and the same for
both agents. For simplicity reasons, we assume that this
set does not change during the dialogue. The agents are
equipped with theories denoted respectively AP
, FP
, P
,
RP
, DefP
, and AC
, FC
, C
, RC
, DefC
. Note that the
two theories may be different in the sense that the agents
may have different sets of arguments, and different 
preference relations. Worst yet, they may have different 
arguments in favor of the same offers. Moreover, these theories
may evolve during the dialogue.
5.1 Evolution of the theories
Before defining formally the evolution of an agent"s theory,
let us first introduce the notion of dialogue moves, or moves
for short.
Definition 10 (Move). A move is a tuple mi = pi,
ai, oi, ti such that:
• pi ∈ {P, C}
• ai ∈ Args(L) ∪ θ1
1
In what follows θ denotes the fact that no argument, or no
offer is given
970 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
• oi ∈ O ∪ θ
• ti ∈ N∗
is the target of the move, such that ti < i
The function Player (resp. Argument, Offer, Target) 
returns the player of the move (i.e. pi) (resp. the argument
of a move, i.e ai, the offer oi, and the target of the move,
ti). Let M denote the set of all the moves that can be built
from {P, C}, Arg(L), O .
Note that the set M is finite since Arg(L) and O are 
assumed to be finite. Let us now see how an agent"s theory
evolves and why. The idea is that if an agent receives an
argument from another agent, it will add the new argument
to its theory. Moreover, since an argument may bring new
information for the agent, thus new arguments can emerge.
Let us take the following example:
Example 6. Suppose that an agent P has the following
propositional knowledge base: ΣP = {x, y → z}. From this
base one cannot deduce z. Let"s assume that this agent 
receives the following argument {a, a → y} that justifies y.
It is clear that now P can build an argument, say {a, a →
y, y → z} in favor of z.
In a similar way, if a received argument is in conflict with the
arguments of the agent i, then those conflicts are also added
to its relation Ri
. Note that new conflicts may arise between
the original arguments of the agent and the ones that emerge
after adding the received arguments to its theory. Those new
conflicts should also be considered. As a direct consequence
of the evolution of the sets Ai
and Ri
, the defeat relation
Defi
is also updated.
The initial theory of an agent i, (i.e. its theory before the
dialogue starts), is denoted by Ai
0, Fi
0, i
0, Ri
0, Defi
0 , with
i ∈ {P, C}. Besides, in this paper, we suppose that the
preference relation i
of an agent does not change during
the dialogue.
Definition 11 (Theory evolution). Let m1, . . ., mt,
. . ., mj be a sequence of moves. The theory of an agent i at
a step t > 0 is: Ai
t, Fi
t , i
t, Ri
t, Defi
t such that:
• Ai
t = Ai
0 ∪ {ai, i = 1, . . . , t, ai = Argument(mi)} ∪
A with A ⊆ Args(L)
• Fi
t = O → 2Ai
t
• i
t = i
0
• Ri
t = Ri
0 ∪ {(ai, aj) | ai = Argument(mi),
aj = Argument(mj), i, j ≤ t, and ai RL aj} ∪ R with
R ⊆ RL
• Defi
t ⊆ Ai
t × Ai
t
The above definition captures the monotonic aspect of an
argument. Indeed, an argument cannot be removed. 
However, its status may change. An argument that is accepted
at step t of the dialogue by an agent may become rejected
at step t + i. Consequently, the status of offers also change.
Thus, the sets Oa, Or, On, and Ons may change from one
step of the dialogue to another. That means for example
that some offers could move from the set Oa to the set Or
and vice-versa. Note that in the definition of Rt, the 
relation RL is used to denote a conflict between exchanged
arguments. The reason is that, such a conflict may not be
in the set Ri
of the agent i. Thus, in order to recognize
such conflicts, we have supposed that the set RL is known
to the agents. This allows us to capture the situation where
an agent is able to prove an argument that it was unable
to prove before, by incorporating in its beliefs some 
information conveyed through the exchange of arguments with
another agent. This, unknown at the beginning of the 
dialogue argument, could give to this agent the possibility to
defeat an argument that it could not by using its initial 
arguments. This could even lead to a change of the status of
these initial arguments and this change would lead to the
one of the associated offers" status.
In what follows, Oi
t,x denotes the set of offers of type x,
where x ∈ {a, n, r, ns}, of the agent i at step t of the 
dialogue. In some places, we can use for short the notation Oi
t
to denote the partition of the set O at step t for agent i.
Note that we have: not(Oi
t,x ⊆ Oi
t+1,x).
5.2 The notion of agreement
As said in the introduction, negotiation is a process aiming
at finding an agreement about some matters. By agreement,
one means a solution that satisfies to the largest possible 
extent the preferences of both agents. In case there is no such
solution, we say that the negotiation fails. In what follows,
we will discuss the different kinds of solutions that may be
reached in a negotiation. The first one is the optimal 
solution. An optimal solution is the best offer for both agents.
Formally:
Definition 12 (Optimal solution). Let O be a set
of offers, and o ∈ O. The offer o is an optimal solution at
a step t ≥ 0 iff o ∈ OP
t,a ∩ OC
t,a
Such a solution does not always exist since agents may have
conflicting preferences. Thus, agents make concessions by
proposing/accepting less preferred offers.
Definition 13 (Concession). Let o ∈ O be an offer.
The offer o is a concession for an agent i iff o ∈ Oi
x such
that ∃Oi
y = ∅, and Oi
y Oi
x.
During a negotiation dialogue, agents exchange first their
most preferred offers, and if these last are rejected, they
make concessions. In this case, we say that their best offers
are no longer defendable. In an argumentation setting, this
means that the agent has already presented all its arguments
supporting its best offers, and it has no counter argument
against the ones presented by the other agent. Formally:
Definition 14 (Defendable offer). Let Ai
t, Fi
t , i
t,
Ri
t, Defi
t be the theory of agent i at a step t > 0 of the 
dialogue. Let o ∈ O such that ∃j ≤ t with Player(mj) = i and
offer(mj) = o. The offer o is defendable by the agent i iff:
• ∃a ∈ Fi
t (o), and k ≤ t s.t. Argument(mk) = a, or
• ∃a ∈ At
\Fi
t (o) s.t. a Defi
t b with
- Argument(mk) = b, k ≤ t, and Player(mk) = i
- l ≤ t, Argument(ml) = a
The offer o is said non-defendable otherwise and NDi
t is the
set of non-defendable offers of agent i at a step t.
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 971
5.3 Negotiation dialogue
Now that we have shown how the theories of the agents
evolve during a dialogue, we are ready to define formally
an argumentation-based negotiation dialogue. For that 
purpose, we need to define first the notion of a legal 
continuation.
Definition 15 (Legal move). A move m is a legal
continuation of a sequence of moves m1, . . . , ml iff j, k < l,
such that:
• Offer(mj) = Offer(mk), and
• Player(mj) = Player(mk)
The idea here is that if the two agents present the same
offer, then the dialogue should terminate, and there is no
longer possible continuation of the dialogue.
Definition 16 (Argumentation-based negotiation).
An argumentation-based negotiation dialogue d between two
agents P and C is a non-empty sequence of moves m1, . . . , ml
such that:
• pi = P iff i is even, and pi = C iff i is odd
• Player(m1) = P, Argument(m1) = θ, Offer(m1) = θ,
and Target(m1) = 02
• ∀ mi, if Offer(mi) = θ, then Offer(mi) oj, ∀ oj ∈
O\(O
Player(mi)
i,r ∪ ND
Player(mi)
i )
• ∀i = 1, . . . , l, mi is a legal continuation of m1, . . . , mi−1
• Target(mi) = mj such that j < i and Player(mi) =
Player(mj)
• If Argument(mi) = θ, then:
- if Offer(mi) = θ then Argument(mi) ∈ F(Offer(mi))
- if Offer(mi) = θ then Argument(mi) Def
Player(mi)
i
Argument(Target(mi))
• i, j ≤ l such that mi = mj
• m ∈ M such that m is a legal continuation of m1, . . . , ml
Let D be the set of all possible dialogues.
The first condition says that the two agents take turn. The
second condition says that agent P starts the negotiation
dialogue by presenting an offer. Note that, in the first turn,
we suppose that the agent does not present an argument.
This assumption is made for strategical purposes. Indeed,
arguments are exchanged as soon as a conflict appears. The
third condition ensures that agents exchange their best 
offers, but never the rejected ones. This condition takes also
into account the concessions that an agent will have to make
if it was established that a concession is the only option for
it at the current state of the dialogue. Of course, as we
have shown in a previous section, an agent may have several
good or acceptable offers. In this case, the agent chooses
one of them randomly. The fourth condition ensures that
the moves are legal. This condition allows to terminate the
dialogue as soon as an offer is presented by both agents.
The fifth condition allows agents to backtrack. The sixth
2
The first move has no target.
condition says that an agent may send arguments in favor
of offers, and in this case the offer should be stated in the
same move. An agent can also send arguments in order to
defeat arguments of the other agent. The next condition
prevents repeating the same move. This is useful for 
avoiding loops. The last condition ensures that all the possible
legal moves have been presented.
The outcome of a negotiation dialogue is computed as
follows:
Definition 17 (Dialogue outcome). Let d = m1, . . .,
ml be a argumentation-based negotiation dialogue. The 
outcome of this dialogue, denoted Outcome, is Outcome(d) =
Offer(ml) iff ∃j < l s.t. Offer(ml) = Offer(mj), and
Player(ml) = Player(mj). Otherwise, Outcome(d) = θ.
Note that when Outcome(d) = θ, the negotiation fails, and
no agreement is reached by the two agents. However, if
Outcome(d) = θ, the negotiation succeeds, and a solution
that is either optimal or a compromise is found.
Theorem 8. ∀di ∈ D, the argumentation-based 
negotiation di terminates.
The above result is of great importance, since it shows that
the proposed protocol avoids loops, and dialogues terminate.
Another important result shows that the proposed protocol
ensures to reach an optimal solution if it exists. Formally:
Theorem 9 (Completeness). Let d = m1, . . . , ml be
a argumentation-based negotiation dialogue. If ∃t ≤ l such
that OP
t,a ∩ OC
t,a = ∅, then Outcome(d) ∈ OP
t,a ∩ OC
t,a.
We show also that the proposed dialogue protocol is sound
in the sense that, if a dialogue returns a solution, then that
solution is for sure a compromise. In other words, that 
solution is a common agreement at a given step of the 
dialogue. We show also that if the negotiation fails, then there
is no possible solution.
Theorem 10 (Soundness). Let d = m1, . . . , ml be a
argumentation-based negotiation dialogue.
1. If Outcome(d) = o, (o = θ), then ∃t ≤ l such that o ∈
OP
t,x ∩ OC
t,y, with x, y ∈ {a, n, ns}.
2. If Outcome(d) = θ, then ∀t ≤ l, OP
t,x ∩ OC
t,y = ∅, ∀
x, y ∈ {a, n, ns}.
A direct consequence of the above theorem is the following:
Property 4. Let d = m1, . . . , ml be a 
argumentationbased negotiation dialogue. If Outcome(d) = θ, then ∀t ≤ l,
• OP
t,r = OC
t,a ∪ OC
t,n ∪ OC
t,ns, and
• OC
t,r = OP
t,a ∪ OP
t,n ∪ OP
t,ns.
6. ILLUSTRATIVE EXAMPLES
In this section we will present some examples in order to
illustrate our general framework.
Example 7 (No argumentation). Let O = {o1, o2}
be the set of all possible offers. Let P and C be two agents,
equipped with the same theory: A, F, , R, Def such that
A = ∅, F(o1) = F(o2) = ∅, = ∅, R = ∅, Def = ∅. In
this case, it is clear that the two offers o1 and o2 are 
nonsupported. The proposed protocol (see Definition 16) will
generate one of the following dialogues:
972 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
P: m1 = P, θ, o1, 0
C: m2 = C, θ, o1, 1
This dialogue ends with o1 as a compromise. Note that this
solution is not considered as optimal since it is not an 
acceptable offer for the agents.
P: m1 = P, θ, o1, 0
C: m2 = C, θ, o2, 1
P: m3 = P, θ, o2, 2
This dialogue ends with o2 as a compromise.
P: m1 = P, θ, o2, 0
C: m2 = C, θ, o2, 1
This dialogue also ends with o2 as a compromise. The last
possible dialgue is the following that ends with o1 as a 
compromise.
P: m1 = P, θ, o2, 0
C: m2 = C, θ, o1, 1
P: m3 = P, θ, o1, 2
Note that in the above example, since there is no exchange
of arguments, the theories of both agents do not change. Let
us now consider the following example.
Example 8 (Static theories). Let O = {o1, o2} be
the set of all possible offers. The theory of agent P is AP
,
FP
, P
, RP
, DefP
such that: AP
= {a1, a2}, FP
(o1) =
{a1}, FP
(o2) = {a2}, P
= {(a1, a2)}, RP
= {(a1, a2), (a2, a1)},
DefP
= {a1, a2}. The argumentation system AP
, DefP
of
this agent will return a1 as an accepted argument, and a2 as
a rejected one. Consequently, the offer o1 is acceptable and
o2 is rejected.
The theory of agent C is AC
, FC
, C
, RC
, DefC
such
that: AC
= {a1, a2}, FC
(o1) = {a1}, FC
(o2) = {a2}, C
=
{(a2, a1)}, RC
= {(a1, a2), (a2, a1)}, DefC
= {a2, a1}. The
argumentation system AC
, DefC
of this agent will return
a2 as an accepted argument, and a1 as a rejected one. 
Consequently, the offer o2 is acceptable and o1 is rejected.
The only possible dialogues that may take place between
the two agents are the following:
P: m1 = P, θ, o1, 0
C: m2 = C, θ, o2, 1
P: m3 = P, a1, o1, 2
C: m4 = C, a2, o2, 3
The second possible dialogue is the following:
P: m1 = P, θ, o1, 0
C: m2 = C, a2, o2, 1
P: m3 = P, a1, o1, 2
C: m4 = C, θ, o2, 3
Both dialogues end with failure. Note that in both dialogues,
the theories of both agents do not change. The reason is that
the exchanged arguments are already known to both agents.
The negotiation fails because the agents have conflicting 
preferences.
Let us now consider an example in which argumentation will
allow agents to reach an agreement.
Example 9 (Dynamic theories). Let O = {o1, o2} be
the set of all possible offers. The theory of agent P is AP
,
FP
, P
, RP
, DefP
such that: AP
= {a1, a2}, FP
(o1)
= {a1}, FP
(o2) = {a2}, P
= {(a1, a2), (a3, a1)}, RP
=
{(a1, a2), (a2, a1)}, DefP
= {(a1, a2)}. The argumentation
system AP
, DefP
of this agent will return a1 as an accepted
argument, and a2 as a rejected one. Consequently, the offer
o1 is acceptable and o2 is rejected.
The theory of agent C is AC
, FC
, C
, RC
, DefC
such
that: AC
= {a1, a2, a3}, FC
(o1) = {a1}, FC
(o2) = {a2},
C
= {(a1, a2), (a3, a1)}, RC
= {(a1, a2), (a2, a1), (a3, a1)},
DefC
= {(a1, a2), (a3, a1)}. The argumentation system
AC
, DefC
of this agent will return a3 and a2 as accepted
arguments, and a1 as a rejected one. Consequently, the offer
o2 is acceptable and o1 is rejected.
The following dialogue may take place between the two
agents:
P: m1 = P, θ, o1, 0
C: m2 = C, θ, o2, 1
P: m3 = P, a1, o1, 2
C: m4 = C, a3, θ, 3
C: m5 = P, θ, o2, 4
At step 4 of the dialogue, the agent P receives the 
argument a3 from P. Thus, its theory evolves as follows: AP
= {a1, a2, a3}, RP
= {(a1, a2), (a2, a1), (a3, a1)}, DefP
=
{(a1, a2), (a3, a1)}. At this step, the argument a1 which was
accepted will become rejected, and the argument a2 which
was at the beginning of the dialogue rejected will become 
accepted. Thus, the offer o2 will be acceptable for the agent,
whereas o1 will become rejected. At this step 4, the offer o2
is acceptable for both agents, thus it is an optimal solution.
The dialogue ends by returning this offer as an outcome.
7. RELATED WORK
Argumentation has been integrated in negotiation 
dialogues at the early nineties by Sycara [12]. In that work, the
author has emphasized the advantages of using 
argumentation in negotiation dialogues, and a specific framework has
been introduced. In [8], the different types of arguments
that are used in a negotiation dialogue, such as threats and
rewards, have been discussed. Moreover, a particular 
framework for negotiation have been proposed. In [9, 13], 
different other frameworks have been proposed. Even if all these
frameworks are based on different logics, and use different
definitions of arguments, they all have at their heart an 
exchange of offers and arguments. However, none of those
proposals explain when arguments can be used within a 
negotiation, and how they should be dealt with by the agent
that receives them. Thus the protocol for handling 
arguments was missing. Another limitation of the above 
frameworks is the fact that the argumentation frameworks they
The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 973
use are quite poor, since they use a very simple 
acceptability semantics. In [2] a negotiation framework that fills the
gap has been suggested. A protocol that handles the 
arguments was proposed. However, the notion of concession
is not modeled in that framework, and it is not clear what
is the status of the outcome of the dialogue. Moreover, it
is not clear how an agent chooses the offer to propose at a
given step of the dialogue. In [1, 7], the authors have 
focused mainly on this decision problem. They have proposed
an argumentation-based decision framework that is used by
agents in order to choose the offer to propose or to accept
during the dialogue. In that work, agents are supposed to
have a beliefs base and a goals base.
Our framework is more general since it does not impose
any specific structure for the arguments, the offers, or the 
beliefs. The negotiation protocol is general as well. Thus this
framework can be instantiated in different ways by creating,
in such manner, different specific argumentation-based 
negotiation frameworks, all of them respecting the same 
properties. Our framework is also a unified one because frameworks
like the ones presented above can be represented within this
framework. For example the decision making mechanism
proposed in [7] for the evaluation of arguments and 
therefore of offers, which is based on a priority relation between
mutually attacked arguments, can be captured by the 
relation defeat proposed in our framework. This relation takes
simultaneously into account the attacking and preference
relations that may exist between two arguments.
8. CONCLUSIONS AND FUTURE WORK
In this paper we have presented a unified and general
framework for argumentation-based negotiation. Like any
other argumentation-based negotiation framework, as it is
evoked in (e.g. [10]), our framework has all the advantages
that argumentation-based negotiation approaches present
when related to the negotiation approaches based either on
game theoretic models (see e.g. [11]) or heuristics ([6]). This
work is a first attempt to formally define the role of 
argumentation in the negotiation process. More precisely, for the
first time, it formally establishes the link that exists between
the status of the arguments and the offers they support, it
defines the notion of concession and shows how it influences
the evolution of the negotiation, it determines how the 
theories of agents evolve during the dialogue and performs an
analysis of the negotiation outcomes. It is also the first time
where a study of the formal properties of the negotiation
theories of the agents as well as of an argumentative 
negotiation dialogue is presented.
Our future work concerns several points. A first point is
to relax the assumption that the set of possible offers is the
same to both agents. Indeed, it is more natural to assume
that agents may have different sets of offers. During a 
negotiation dialogue, these sets will evolve. Arguments in favor
of the new offers may be built from the agent theory. Thus,
the set of offers will be part of the agent theory. Another
possible extension of this work would be to allow agents
to handle both arguments PRO and CONS offers. This is
more akin to the way human take decisions. Considering
both types of arguments will refine the evaluation of the
offers status. In the proposed model, a preference relation
between offers is defined on the basis of the partition of the
set of offers. This preference relation can be refined. For
instance, among the acceptable offers, one may prefer the
offer that is supported by the strongest argument. In [4], 
different criteria have been proposed for comparing decisions.
Our framework can thus be extended by integrating those
criteria. Another interesting point to investigate is that of
considering negotiation dialogues between two agents with
different profiles. By profile, we mean the criterion used by
an agent to compare its offers.
9. REFERENCES
[1] L. Amgoud, S. Belabbes, and H. Prade. Towards a
formal framework for the search of a consensus
between autonomous agents. In Proceedings of the 4th
International Joint Conference on Autonomous Agents
and Multi-Agents systems, pages 537-543, 2005.
[2] L. Amgoud, S. Parsons, and N. Maudet. Arguments,
dialogue, and negotiation. In Proceedings of the 14th
European Conference on Artificial Intelligence, 2000.
[3] L. Amgoud and H. Prade. Reaching agreement
through argumentation: A possibilistic approach. In 9
th International Conference on the Principles of
Knowledge Representation and Reasoning, KR"2004,
2004.
[4] L. Amgoud and H. Prade. Explaining qualitative
decision under uncertainty by argumentation. In 21st
National Conference on Artificial Intelligence,
AAAI"06, pages 16 - 20, 2006.
[5] P. M. Dung. On the acceptability of arguments and its
fundamental role in nonmonotonic reasoning, logic
programming and n-person games. Artificial
Intelligence, 77:321-357, 1995.
[6] N. R. Jennings, P. Faratin, A. R. Lumuscio,
S. Parsons, and C. Sierra. Automated negotiation:
Prospects, methods and challenges. International
Journal of Group Decision and Negotiation, 2001.
[7] A. Kakas and P. Moraitis. Adaptive agent negotiation
via argumentation. In Proceedings of the 5th
International Joint Conference on Autonomous Agents
and Multi-Agents systems, pages 384-391, 2006.
[8] S. Kraus, K. Sycara, and A. Evenchik. Reaching
agreements through argumentation: a logical model
and implementation. Artificial Intelligence, 104:1-69,
1998.
[9] S. Parsons and N. R. Jennings. Negotiation through
argumentation-a preliminary report. In Proceedings
of the 2nd International Conference on Multi Agent
Systems, pages 267-274, 1996.
[10] I. Rahwan, S. D. Ramchurn, N. R. Jennings,
P. McBurney, S. Parsons, and E. Sonenberg.
Argumentation-based negotiation. Knowledge
Engineering Review, 18 (4):343-375, 2003.
[11] J. Rosenschein and G. Zlotkin. Rules of Encounter:
Designing Conventions for Automated Negotiation
Among Computers,. MIT Press, Cambridge,
Massachusetts, 1994., 1994.
[12] K. Sycara. Persuasive argumentation in negotiation.
Theory and Decision, 28:203-242, 1990.
[13] F. Tohm´e. Negotiation and defeasible reasons for
choice. In Proceedings of the Stanford Spring
Symposium on Qualitative Preferences in Deliberation
and Practical Reasoning, pages 95-102, 1997.
974 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07)
